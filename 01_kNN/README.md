# 1. 模型实现
原理很简单，有监督学习，没有显式的训练过程，分类和回归都可以用。<br>
以分类任务为例，新来了一个样本，像判断它的类别，那么就依次计算它和每一个训练样本的距离，选取k个与它最接近的训练样本，看看里边什么类别最多，那就把这个样本预测成什么类别，简单粗暴。<br>
写代码的话，我觉得需要注意2点就可以：
一是在算新样本和所有训练样本的距离时，不要用for循环去遍历(O(m))，尽量用numpy的矩阵运算，这样可以提速（利用cpu/gpu的并行处理能力）<br>
二是python中，dict的排序和遍历都需要用dict.items()转化成tupple list在做(好吧，这个是说给我自己的...)<br>
至于优化的话，主要是如何快速的找出k个最近邻，要么brute蛮力搜索O(m)，要么使用高级的数据结构——kd-tree(就是二叉树,以中值切分构造的树，每个结点是一个超矩形，可参照李航老师的《统计学习方法》)，ball-tree(为了克服kd树高纬失效而发明的，其构造过程是以质心C和半径r分割样本空间，每个节点是一个超球体)<br>
基本实现就是这么多了，下面会用kNN来做一些简单的应用。
