{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### @Time    : 2019/4/5 15:09\n",
    "##### @Author  : ChanLiang\n",
    "##### @Github  ：https://github.com/ChanLiang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression 多分类（iris数据集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import array\n",
    "import time\n",
    "import scipy.sparse\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 制作数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集占70%，测试集占30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, Y = iris.data, iris.target\n",
    "#print (X)\n",
    "#print (Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 开始编写多分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression(object):\n",
    "    #######################################################################################\n",
    "    \"\"\" 初始化分类器对象 \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, num_classes, lamda):\n",
    "    \n",
    "        \"\"\" 初始化分类器对象的参数\"\"\"\n",
    "    \n",
    "        self.input_size  = input_size  # 输入向量的大小（一个输入实例x的特征数）\n",
    "        self.num_classes = num_classes # 总共有多少个类\n",
    "        self.lamda       = lamda       # 规则化系数\n",
    "        \n",
    "        \"\"\" 每个类都有自己的LR参数，将3个不同类的参数按行排列形成一个参数矩阵的'扁平形式':theta.shape = (3 * 4, 1) \"\"\"\n",
    "        \n",
    "        rand = numpy.random.RandomState(int(time.time()))\n",
    "        # theta.shape = (num_classes * input_size, 1)\n",
    "        self.theta = 0.005 * numpy.asarray(rand.normal(size = (num_classes * input_size, 1)))\n",
    "    \n",
    "    #######################################################################################\n",
    "    \"\"\" 返回一组输入数据的GroundTruth矩阵(压缩存储)：shape = (k x m)，每一列代表一个样本输入哪一个类(one-hot) \"\"\"\n",
    "        \n",
    "    def getGroundTruth(self, labels):\n",
    "    \n",
    "        \"\"\" 准备构建 groundtruth matrix 的数据\"\"\"\n",
    "    \n",
    "        data   = numpy.ones(len(labels))\n",
    "        indices = numpy.array(labels).flatten()  # 变成一维的\n",
    "        indptr = numpy.arange(len(labels)+1)\n",
    "        \n",
    "        \"\"\" 构建 groundtruth matrix ，注意这里是按行构建的，需要转置一下再返回\"\"\"\n",
    "        \n",
    "        ground_truth = scipy.sparse.csr_matrix((data, indices, indptr))  # m x k\n",
    "        ground_truth = numpy.transpose(ground_truth.todense())  # 转置成k x m\n",
    "        \n",
    "        return ground_truth\n",
    "        \n",
    "    #######################################################################################\n",
    "    \"\"\" 返回代价函数的值，以及组合参数 theta 的梯度 \"\"\"\n",
    "        \n",
    "    def softmaxCost(self, theta, input, labels):\n",
    "    \n",
    "        \"\"\" 构建 groundtruth matrix \"\"\"\n",
    "    \n",
    "        ground_truth = self.getGroundTruth(labels)\n",
    "        \n",
    "        \"\"\" 调整 theta 的形状，以方便计算 \"\"\"\n",
    "        \n",
    "        theta = theta.reshape(self.num_classes, self.input_size)\n",
    "        \n",
    "        \"\"\" 计算概率矩阵 probabilities matrix: (k, m)—— m个样本横向排列，每一列代表该样本属于不同类的概率 \"\"\"\n",
    "        \n",
    "        theta_x       = numpy.dot(theta, input)\n",
    "        hypothesis    = numpy.exp(theta_x)      \n",
    "        probabilities = hypothesis / numpy.sum(hypothesis, axis = 0)\n",
    "        \n",
    "        \"\"\" 计算 经验风险 部分 \"\"\"\n",
    "        \n",
    "        cost_examples    = numpy.multiply(ground_truth, numpy.log(probabilities))\n",
    "        traditional_cost = -(numpy.sum(cost_examples) / input.shape[1])\n",
    "        \n",
    "        \"\"\" 计算 规则化项 部分：否则每当求得一个优化参数时，如果将这个参数的每一项都减掉同一个数，其得到的损失函数值也是一样的 \"\"\"\n",
    "        \n",
    "        theta_squared = numpy.multiply(theta, theta)\n",
    "        weight_decay  = 0.5 * self.lamda * numpy.sum(theta_squared)  # axis取None，即将数组/矩阵中的元素全部加起来，得到一个和\n",
    "        \n",
    "        \"\"\" 将 两部分 加起来，得到最终的 代价函数值 \"\"\"\n",
    "        \n",
    "        cost = traditional_cost + weight_decay\n",
    "        \n",
    "        \"\"\" 计算 theta 的梯度 \"\"\"\n",
    "        \n",
    "        theta_grad = -numpy.dot(ground_truth - probabilities, numpy.transpose(input))\n",
    "        theta_grad = theta_grad / input.shape[1] + self.lamda * theta\n",
    "        theta_grad = numpy.array(theta_grad)\n",
    "        theta_grad = theta_grad.flatten()\n",
    "        \n",
    "        return [cost, theta_grad]\n",
    "    \n",
    "    #######################################################################################\n",
    "    \"\"\" 对一组输入，返回他们对应的预测值 \"\"\"\n",
    "            \n",
    "    def softmaxPredict(self, theta, input):\n",
    "    \n",
    "        \"\"\" 同上 \"\"\"\n",
    "        # K * m\n",
    "        theta = theta.reshape(self.num_classes, self.input_size)\n",
    "        \n",
    "        \"\"\" 计算 概率矩阵 \"\"\"\n",
    "        \n",
    "        theta_x       = numpy.dot(theta, input)\n",
    "        hypothesis    = numpy.exp(theta_x)      \n",
    "        probabilities = hypothesis / numpy.sum(hypothesis, axis = 0)\n",
    "        \n",
    "        \"\"\" 基于 概率矩阵 给出预测值 \"\"\"\n",
    "        \n",
    "        predictions = numpy.zeros((input.shape[1], 1))\n",
    "        predictions[:, 0] = numpy.argmax(probabilities, axis = 0)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 初始化数据, 用训练集训练模型 再该模型在测试集上进行预测 \"\"\"\n",
    "\n",
    "def executeSoftmaxRegression():\n",
    "    \n",
    "    \"\"\" 初始化分类器的参数 \"\"\"\n",
    "    \n",
    "    input_size     = 4    # input vector size\n",
    "    num_classes    = 3     # number of classes\n",
    "    lamda          = 0.0001 # weight decay parameter\n",
    "    max_iterations = 10    # number of optimization iterations\n",
    "    \n",
    "    \"\"\" 初始化训练数据 和 测试数据\"\"\"\n",
    "    \n",
    "    training_data = X_train.T\n",
    "    training_labels = Y_train\n",
    "    test_data  = X_test.T \n",
    "    test_labels = Y_test.reshape(len(Y_test), 1)\n",
    "    \n",
    "    \"\"\" 初始化一个分类器 \"\"\"\n",
    "    \n",
    "    regressor = SoftmaxRegression(input_size, num_classes, lamda)\n",
    "    \n",
    "    \"\"\" 运行 L-BFGS 算法，获得最优的参数值 \"\"\"\n",
    "    \n",
    "    opt_solution  = scipy.optimize.minimize(regressor.softmaxCost, regressor.theta, \n",
    "                                            args = (training_data, training_labels,), method = 'L-BFGS-B', \n",
    "                                            jac = True, options = {'maxiter': max_iterations})\n",
    "    opt_theta     = opt_solution.x\n",
    "    \n",
    "    \"\"\" 用训练好的模型在测试集上做预测 \"\"\"\n",
    "    \n",
    "    predictions = regressor.softmaxPredict(opt_theta, test_data)\n",
    "    \n",
    "    \"\"\" 打印测试集上的准确率 \"\"\"\n",
    "#     print (test_labels)\n",
    "#     print (predictions)\n",
    "    correct = test_labels[:, 0] == predictions[:, 0]\n",
    "    print (\"\"\"Accuracy :\"\"\", numpy.mean(correct))\n",
    "    \n",
    "executeSoftmaxRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结束"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
